# -*- coding: utf-8 -*-
"""Graduate Admission Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o4Nw1_dmXuqAwmOMk-Z2uxhh3lEgr61e
"""



"""**Data**

We plan to use the dataset "Graduate Admission 2" from Kaggle for this project.

GRE Scores (out of 340)

TOEFL Scores (out of 120)

University Rating (out of 5)

Statement of Purpose and Letter of Recommendation Strength (out of 5)

Undergraduate GPA (out of 10)

Research Experience (either 0 or 1)

Chance of Admit (ranging from 0 to 1)


**Project Description and Goals**

Every student that applies to graduate school worries about whether they will get in or not. We will try to discover the components of a graduate school application that lead to admission into the program. Our minimum goal is to determine which are the most important components of an application and our maximum goal is to determine the most ideal application in terms of chance of admission (condfidence of admission). 


**Methods**

We will use (at least) the following Machine learning techniques. 
*   Linear Regression
*   Logisitic  Regression
*   Random Forest


**Member Roles**

Sophia Chrysler

Naomi Curtis

Catherine Donner

**Relationship to our Backgrounds**

Every member of this group is interested in the possibility of attending a graduate program. Therefore, this analysis will be helpful for us in creating the most successful application in the future. 
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("Admission_Predict.csv")
#drop serial number
#we can use linear, svm, decision tree, deep learning
#use MAE, MSE, RMSE to compare machine learning algorthims (cross-validation for regression lecture)
#r2_score is best perfromance
#import SVR for regression
#import decision tree regressor instead of decision tree classifyer
#cross validation for all three models

df #note "Chance of Admit" is "Chance of Admit "

df['ChanceOfAdmit']=[1 if chance>=0.75  else 0 for chance in df['Chance of Admit ']]
#this will give a boolean for chance of admit
#we can use linear, svm, decision tree, deep learning

df

plt.figure(figsize=(12,8))
sns.scatterplot(x='CGPA',y='GRE Score',hue='ChanceOfAdmit', palette = 'plasma', data=df,alpha=0.7)

#import needed libraries for KNN classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
df = df.drop('Chance of Admit ', axis = 1)

X = df.drop('ChanceOfAdmit',axis=1)
y = df['ChanceOfAdmit']

X

y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

#X_train

#X_test

#y_train

#y_test

scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

#scaled_X_train

#scaled_X_test

knn_model = KNeighborsClassifier(n_neighbors=3)



knn_model.fit(X_train,y_train)

knn_model.score(X_train, y_train)

knn_model.score(X_test, y_test)

y_pred = knn_model.predict(X_test)

y_pred

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, plot_confusion_matrix

accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

plot_confusion_matrix(knn_model, X_test, y_test)

print(classification_report(y_test,y_pred))

from sklearn.linear_model import LogisticRegressionCV
log_model = LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,
                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,
                     max_iter=1000, multi_class='auto', n_jobs=None,
                     penalty='l2', random_state=None, refit=True, scoring=None,
                     solver='lbfgs', tol=0.0001, verbose=0)
log_model.fit(scaled_X_train,y_train)

log_model.score(scaled_X_train,y_train)

from sklearn.metrics import classification_report,plot_confusion_matrix
plot_confusion_matrix(log_model,scaled_X_test,y_test)

log_model.score(scaled_X_test,y_test)

y_pred = log_model.predict(scaled_X_test)
print(classification_report(y_test,y_pred))

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix,accuracy_score
#random forest classifier model, confusion matrix, and score
rf_model = RandomForestClassifier()
rf_model.fit(scaled_X_train,y_train)
rf_model.score(scaled_X_train,y_train)

y_pred = rf_model.predict(scaled_X_test)
print(classification_report(y_test,y_pred))

#Cross validation scoring
from sklearn.model_selection import cross_validate,cross_val_score

#knn_model
scores = cross_val_score(knn_model,X_train,y_train,scoring='accuracy',cv=10)
scores
abs(scores.mean())

scores = cross_validate(knn_model,X_train,y_train,scoring=['accuracy','f1_weighted'],cv=10)
pd.DataFrame(scores).mean()

#log_model
scores = cross_val_score(log_model,X_train,y_train,scoring='accuracy',cv=10)
scores
abs(scores.mean())

scores = cross_validate(log_model,X_train,y_train,scoring=['accuracy','f1_weighted'],cv=10)
pd.DataFrame(scores).mean()

#rf_model
scores = cross_val_score(rf_model,X_train,y_train,scoring='accuracy',cv=10)
scores
abs(scores.mean())

scores = cross_validate(rf_model,X_train,y_train,scoring=['accuracy','f1_weighted'],cv=10)
pd.DataFrame(scores).mean()



"""Questions:

1. How do we graph a random forest plot?
2. Should we drop serial number from the data? 
3. Besides a cross validation, what other ways should we compare metrics?
4. Should our conclusions be to decide which is the best machine learning algorithm for this data, or are we trying to conclude something else?
5. The project description mentions source code. Is that just the code in this document, or is that something different?
"""